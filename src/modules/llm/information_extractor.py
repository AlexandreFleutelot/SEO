# -*- coding: utf-8 -*-
"""
Information Extractor - Extraction des marques et entit√©s depuis les r√©ponses LLM
Module sp√©cialis√© dans la d√©tection et l'analyse des informations cl√©s
"""

import re
from typing import Dict, List, Any, Optional
from urllib.parse import urlparse


class InformationExtractor:
    """Extracteur d'informations (marques, entit√©s, citations) depuis les r√©ponses LLM"""
    
    def __init__(self):
        # Patterns pour d√©tecter les sections structur√©es
        self.section_patterns = {
            'marques': [
                r'üè∑Ô∏è\s*MARQUES?\s*MENTIONN[E√â]ES?:',
                r'MARQUES?\s*[E√â]T\s*ENTREPRISES?:',
                r'ENTREPRISES?\s*CIT√âES?:'
            ],
            'sources': [
                r'üîó\s*SOURCES?\s*CONSULT[E√â]ES?:',
                r'SOURCES?\s*ET\s*R[E√â]F[E√â]RENCES?:',
                r'BIBLIOGRAPHIE:'
            ],
            'classement': [
                r'üìä\s*CLASSEMENT:',
                r'ORDRE\s*D[\'\']IMPORTANCE:',
                r'HI[E√â]RARCHIE:'
            ]
        }
    
    
    def extraire_marques_completes(self, reponse_llm: str) -> List[Dict[str, Any]]:
        """
        Extrait toutes les marques mentionn√©es dans une r√©ponse LLM
        
        Args:
            reponse_llm: Texte de la r√©ponse du LLM
            
        Returns:
            list: Marques d√©tect√©es avec m√©tadonn√©es
        """
        print("    üè∑Ô∏è Extraction des marques...")
        
        marques = []
        
        # Strat√©gie 1: Chercher dans les sections structur√©es
        marques.extend(self._extraire_marques_sections_structurees(reponse_llm))
        
        # Strat√©gie 2: D√©tection par patterns si pas assez trouv√©
        if len(marques) < 3:
            marques.extend(self._detecter_marques_patterns(reponse_llm))
        
        # Strat√©gie 3: Analyse par capitalisation et contexte
        marques.extend(self._detecter_marques_capitalisation(reponse_llm))
        
        # D√©duplication et enrichissement
        marques_finales = self._deduplication_et_enrichissement_marques(marques, reponse_llm)
        
        print(f"    ‚úÖ {len(marques_finales)} marques extraites")
        return marques_finales
    
    
    def extraire_ordre_citations(self, reponse_llm: str) -> List[Dict[str, Any]]:
        """
        Extrait l'ordre d'importance/citation depuis une r√©ponse LLM
        
        Args:
            reponse_llm: Texte de la r√©ponse du LLM
            
        Returns:
            list: Citations ordonn√©es avec positions
        """
        print("    üìä Extraction ordre des citations...")
        
        citations = []
        
        # Chercher dans les sections de classement
        for pattern in self.section_patterns['classement']:
            section = self._extraire_section_texte(reponse_llm, pattern)
            if section:
                citations.extend(self._parser_elements_ordonnes(section))
        
        # Si pas de section d√©di√©e, chercher les listes num√©rot√©es
        if not citations:
            citations = self._detecter_listes_numerotees(reponse_llm)
        
        print(f"    ‚úÖ {len(citations)} √©l√©ments dans l'ordre des citations")
        return citations
    
    
    def _extraire_marques_sections_structurees(self, texte: str) -> List[Dict[str, Any]]:
        """Extrait les marques depuis les sections structur√©es"""
        marques = []
        
        for pattern in self.section_patterns['marques']:
            section = self._extraire_section_texte(texte, pattern)
            if section:
                # Parser les √©l√©ments de la section
                elements = self._parser_elements_listes(section)
                
                for element in elements:
                    nom_marque, description = self._separer_nom_description(element)
                    if nom_marque:
                        marques.append({
                            'nom': nom_marque,
                            'description': description,
                            'source_detection': 'section_structuree',
                            'element_brut': element
                        })
        
        return marques
    
    
    def _detecter_marques_patterns(self, texte: str) -> List[Dict[str, Any]]:
        """D√©tecte les marques via patterns sp√©cifiques"""
        marques = []
        
        # Patterns sp√©cifiques aux marques/entreprises
        patterns = [
            r'\b([A-Z][a-z]+\s+[A-Z][a-z]+)\s+(?:est|propose|offre|fournit)',  # "Boursorama Banque propose"
            r'(?:chez|avec|par)\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)',          # "chez Orange Bank"
            r'\b([A-Z][a-z]+\s*!?)\s+(?:se|dispose|permet)',                  # "Hello bank! se"
            r'(?:banque|soci√©t√©|groupe|entreprise)\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)', # "banque Fortuneo"
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, texte, re.MULTILINE)
            for match in matches:
                nom_marque = match.group(1).strip()
                
                # Filtrer les faux positifs courants
                if self._est_nom_marque_valide(nom_marque):
                    marques.append({
                        'nom': nom_marque,
                        'description': '',
                        'source_detection': 'pattern_contextuel',
                        'contexte_detection': match.group(0)
                    })
        
        return marques
    
    
    def _detecter_marques_capitalisation(self, texte: str) -> List[Dict[str, Any]]:
        """D√©tecte les marques par analyse de capitalisation"""
        marques = []
        
        # Pattern pour mots/expressions capitalis√©s
        pattern_caps = r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b'
        
        # Compteur de fr√©quence pour identifier les vrais noms de marque
        candidats = {}
        
        for match in re.finditer(pattern_caps, texte):
            candidat = match.group(0).strip()
            
            # Filtrer les mots courants qui ne sont pas des marques
            if (len(candidat) > 2 and 
                candidat not in ['Le', 'La', 'Les', 'Un', 'Une', 'Ce', 'Cette', 'Dans', 'Pour'] and
                not candidat.startswith(('Http', 'Www'))):
                
                candidats[candidat] = candidats.get(candidat, 0) + 1
        
        # Garder les candidats mentionn√©s plusieurs fois ou avec des indicateurs de marque
        for nom, freq in candidats.items():
            if freq >= 2 or self._a_indicateurs_marque(texte, nom):
                marques.append({
                    'nom': nom,
                    'description': '',
                    'source_detection': 'capitalisation',
                    'frequence': freq
                })
        
        return marques
    
    
    def _deduplication_et_enrichissement_marques(self, marques: List[Dict[str, Any]], 
                                               texte_complet: str) -> List[Dict[str, Any]]:
        """D√©duplique et enrichit la liste des marques"""
        marques_uniques = {}
        
        for marque in marques:
            nom = marque['nom'].strip()
            
            # Normaliser le nom (g√©rer les variations)
            nom_normalise = self._normaliser_nom_marque(nom)
            
            if nom_normalise not in marques_uniques:
                # Enrichir avec des informations du texte complet
                marque_enrichie = marque.copy()
                marque_enrichie['nom'] = nom  # Garder le nom original
                marque_enrichie['mentions'] = texte_complet.count(nom)
                marque_enrichie['contexte'] = self._extraire_contexte_marque(texte_complet, nom)
                marque_enrichie['type_entite'] = self._classifier_type_entite(nom, texte_complet)
                
                marques_uniques[nom_normalise] = marque_enrichie
            else:
                # Fusionner les informations si marque d√©j√† pr√©sente
                marque_existante = marques_uniques[nom_normalise]
                
                # Prendre la description la plus compl√®te
                if not marque_existante.get('description') and marque.get('description'):
                    marque_existante['description'] = marque['description']
                
                # Combiner les sources de d√©tection
                sources = marque_existante.get('source_detection', '')
                nouvelle_source = marque.get('source_detection', '')
                if nouvelle_source and nouvelle_source not in sources:
                    marque_existante['source_detection'] = f"{sources}, {nouvelle_source}"
        
        return list(marques_uniques.values())
    
    
    def _parser_elements_ordonnes(self, section: str) -> List[Dict[str, Any]]:
        """Parse une section avec √©l√©ments ordonn√©s"""
        elements = []
        
        # Pattern pour √©l√©ments num√©rot√©s
        pattern = r'(\d+)\.\s*([^\n]+?)(?:\s*[-‚Äì]\s*([^\n]+))?'
        
        for match in re.finditer(pattern, section, re.MULTILINE):
            position = int(match.group(1))
            element = match.group(2).strip()
            raison = match.group(3).strip() if match.group(3) else ""
            
            elements.append({
                'position': position,
                'element': element,
                'raison': raison,
                'score_importance': max(0, 100 - (position - 1) * 10)  # Score d√©croissant
            })
        
        return elements
    
    
    def _detecter_listes_numerotees(self, texte: str) -> List[Dict[str, Any]]:
        """D√©tecte les listes num√©rot√©es dans tout le texte"""
        listes = []
        
        # Chercher les patterns de listes num√©rot√©es
        pattern = r'(?:^|\n)(\d+)[\.\)]\s+([^\n]+)'
        
        matches = list(re.finditer(pattern, texte, re.MULTILINE))
        
        # Garder seulement les s√©quences coh√©rentes (1, 2, 3...)
        if len(matches) >= 3:  # Au moins 3 √©l√©ments pour consid√©rer comme liste
            for match in matches:
                position = int(match.group(1))
                element = match.group(2).strip()
                
                listes.append({
                    'position': position,
                    'element': element,
                    'raison': '',
                    'score_importance': max(0, 100 - (position - 1) * 10)
                })
        
        return listes
    
    
    def _extraire_section_texte(self, texte: str, pattern_debut: str, pattern_fin: str = None) -> str:
        """Extrait une section du texte entre deux marqueurs"""
        start_match = re.search(pattern_debut, texte, re.IGNORECASE)
        if not start_match:
            return ""
        
        start = start_match.end()
        
        if pattern_fin:
            end_match = re.search(pattern_fin, texte[start:], re.IGNORECASE)
            if end_match:
                end = start + end_match.start()
                return texte[start:end].strip()
        
        # Si pas de pattern de fin, prendre jusqu'√† la prochaine section ou fin
        next_section_patterns = [
            r'\n\n[üîçüè∑Ô∏èüîóüí≠üìä]',  # Prochaine section avec emoji
            r'\n\n[A-Z]{2,}:',      # Prochaine section en majuscules
            r'\n\n\d+\.',           # Prochaine liste num√©rot√©e
        ]
        
        end = len(texte)
        for pattern in next_section_patterns:
            match = re.search(pattern, texte[start:])
            if match:
                end = min(end, start + match.start())
        
        return texte[start:end].strip()
    
    
    def _parser_elements_listes(self, section: str) -> List[str]:
        """Parse les √©l√©ments d'une liste (num√©rot√©e ou √† puces)"""
        elements = []
        
        # Patterns pour diff√©rents types de listes
        patterns = [
            r'^\d+\.\s*(.+)$',           # 1. Element
            r'^[-\*\‚Ä¢]\s*(.+)$',         # - Element ou * Element
            r'^([A-Z][^\n]+)$',          # Ligne commen√ßant par majuscule
        ]
        
        lignes = section.split('\n')
        
        for ligne in lignes:
            ligne = ligne.strip()
            if not ligne:
                continue
                
            for pattern in patterns:
                match = re.match(pattern, ligne)
                if match:
                    elements.append(match.group(1).strip())
                    break
        
        return elements
    
    
    def _separer_nom_description(self, element: str) -> tuple:
        """S√©pare un nom de marque de sa description"""
        # Patterns de s√©paration courants
        separateurs = [' - ', ' ‚Äì ', ' : ', ' (', ' |']
        
        for sep in separateurs:
            if sep in element:
                parties = element.split(sep, 1)
                nom = parties[0].strip()
                description = parties[1].strip().rstrip(')')
                return nom, description
        
        # Si pas de s√©parateur, tout est consid√©r√© comme nom
        return element.strip(), ""
    
    
    def _est_nom_marque_valide(self, nom: str) -> bool:
        """V√©rifie si un nom est probablement une vraie marque"""
        # Filtrer les faux positifs courants
        faux_positifs = {
            'France', 'French', 'European', 'Global', 'International',
            'Service', 'Services', 'Client', 'Clients', 'Premium',
            'Standard', 'Classic', 'Basic', 'Advanced', 'Pro'
        }
        
        return (len(nom) > 1 and 
                nom not in faux_positifs and
                not nom.isdigit() and
                not nom.lower() in ['le', 'la', 'les', 'un', 'une', 'des'])
    
    
    def _a_indicateurs_marque(self, texte: str, nom: str) -> bool:
        """V√©rifie si un nom a des indicateurs sugg√©rant que c'est une marque"""
        # Chercher des indicateurs contextuels
        indicateurs = [
            f'{nom} propose', f'{nom} offre', f'{nom} permet',
            f'chez {nom}', f'avec {nom}', f'par {nom}',
            f'{nom} est une', f'{nom} est un', f'{nom} dispose'
        ]
        
        return any(indicateur.lower() in texte.lower() for indicateur in indicateurs)
    
    
    def _normaliser_nom_marque(self, nom: str) -> str:
        """Normalise un nom de marque pour la d√©duplication"""
        # Supprimer les caract√®res sp√©ciaux et normaliser la casse
        nom_norm = re.sub(r'[^\w\s]', '', nom.lower().strip())
        
        # G√©rer les variations communes
        variations = {
            'hello bank': 'hellobank',
            'credit agricole': 'creditagricole',
            'societe generale': 'societegenerale',
            'bnp paribas': 'bnpparibas'
        }
        
        return variations.get(nom_norm, nom_norm)
    
    
    def _extraire_contexte_marque(self, texte: str, marque: str, rayon: int = 150) -> str:
        """Extrait le contexte autour d'une marque"""
        index = texte.lower().find(marque.lower())
        if index == -1:
            return ""
        
        debut = max(0, index - rayon)
        fin = min(len(texte), index + len(marque) + rayon)
        
        return texte[debut:fin].strip()
    
    
    def _classifier_type_entite(self, nom: str, contexte: str) -> str:
        """Classifie le type d'entit√© (banque, assurance, etc.)"""
        nom_lower = nom.lower()
        contexte_lower = contexte.lower()
        
        # Classifications par mots-cl√©s
        if any(mot in contexte_lower for mot in ['banque', 'cr√©dit', 'compte', 'carte']):
            return 'banque'
        elif any(mot in contexte_lower for mot in ['assurance', 'assureur', 'mutuelle']):
            return 'assurance'
        elif any(mot in contexte_lower for mot in ['investissement', 'bourse', 'trading']):
            return 'investissement'
        elif any(mot in contexte_lower for mot in ['n√©obanque', 'fintech']):
            return 'n√©obanque'
        else:
            return 'entreprise'
    
    
    def generer_rapport_extraction(self, marques: List[Dict[str, Any]], 
                                 citations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """G√©n√®re un rapport sur l'extraction d'informations"""
        
        rapport = {
            'marques': {
                'total': len(marques),
                'par_source_detection': {},
                'par_type_entite': {},
                'mentions_totales': 0
            },
            'citations': {
                'total': len(citations),
                'elements_ordonnes': bool(citations)
            }
        }
        
        for marque in marques:
            # Source de d√©tection
            source = marque.get('source_detection', 'inconnue')
            rapport['marques']['par_source_detection'][source] = rapport['marques']['par_source_detection'].get(source, 0) + 1
            
            # Type d'entit√©
            type_entite = marque.get('type_entite', 'inconnue')
            rapport['marques']['par_type_entite'][type_entite] = rapport['marques']['par_type_entite'].get(type_entite, 0) + 1
            
            # Mentions
            rapport['marques']['mentions_totales'] += marque.get('mentions', 0)
        
        return rapport