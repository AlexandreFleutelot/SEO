# -*- coding: utf-8 -*-
"""
Multi-LLM Analyzer - Orchestrateur principal refactorisÃ©
Analyse intelligente avec plusieurs LLM pour extraction d'informations et sentiment
"""

from datetime import datetime
from typing import Dict, List, Any, Optional

from .llm_providers import LLMProviderManager
from .url_extractor import URLExtractor
from .information_extractor import InformationExtractor
from .sentiment_analyzer import SentimentAnalyzer
from .report_generator import MultiLLMReportGenerator


class MultiLLMAnalyzer:
    """
    Analyseur Multi-LLM refactorisÃ© - Orchestrateur principal
    Coordonne tous les modules spÃ©cialisÃ©s pour une analyse complÃ¨te
    """
    
    def __init__(self):
        """Initialise l'analyseur avec tous ses composants"""
        print("ğŸ¤– Initialisation Multi-LLM Analyzer v2.0...")
        
        # Initialiser les composants
        self.llm_manager = LLMProviderManager()
        self.url_extractor = URLExtractor(self.llm_manager)
        self.info_extractor = InformationExtractor()
        self.sentiment_analyzer = SentimentAnalyzer(self.llm_manager)
        self.report_generator = MultiLLMReportGenerator()
        
        if not self.llm_manager.has_available_providers():
            print("âŒ Aucun provider LLM disponible")
            raise RuntimeError("Pas de clÃ©s API LLM configurÃ©es")
    
    
    def analyser_question_complete(self, question: str, contexte: str = "") -> Dict[str, Any]:
        """
        Analyse complÃ¨te d'une question avec tous les LLM disponibles
        
        Args:
            question: Question Ã  analyser
            contexte: Contexte optionnel
            
        Returns:
            dict: RÃ©sultats complets de l'analyse
        """
        print("ğŸš€ DÃ‰BUT ANALYSE MULTI-LLM v2.0")
        print(f"â“ Question: {question}")
        print(f"ğŸ“ Contexte: {contexte[:100]}..." if len(contexte) > 100 else f"ğŸ“ Contexte: {contexte}")
        print("=" * 80)
        
        # Initialiser la structure des rÃ©sultats
        resultats = {
            'question': question,
            'contexte': contexte,
            'timestamp': datetime.now().isoformat(),
            'providers_utilises': [],
            'reponses_brutes': {},
            'marques_detectees': {},
            'sources_extraites': {},
            'citations_ordonnees': {},
            'sentiment_marques': {},
            'sentiment_sources': {},
            'rapport_urls': {},
            'statistiques': {},
            'rapport_consolide': {}
        }
        
        try:
            # === Ã‰TAPE 1: COLLECTE DES RÃ‰PONSES LLM ===
            print("ğŸ“¥ COLLECTE DES RÃ‰PONSES")
            print("-" * 40)
            
            prompt = self._construire_prompt_extraction(question, contexte)
            reponses = self.llm_manager.query_all_providers(prompt)
            
            resultats['reponses_brutes'] = reponses
            resultats['providers_utilises'] = [p for p, r in reponses.items() if r is not None]
            
            if not resultats['providers_utilises']:
                print("âŒ Aucune rÃ©ponse LLM obtenue")
                return resultats
            
            # === Ã‰TAPE 2: EXTRACTION DES INFORMATIONS ===
            print("\nğŸ“Š EXTRACTION DES INFORMATIONS")
            print("-" * 40)
            
            for provider_name in resultats['providers_utilises']:
                reponse_text = reponses[provider_name]
                print(f"ğŸ¯ Extraction {provider_name.upper()}...")
                
                # Extraire marques
                marques = self.info_extractor.extraire_marques_completes(reponse_text)
                resultats['marques_detectees'][provider_name] = marques
                
                # Extraire URLs/sources
                sources = self.url_extractor.extraire_urls_depuis_reponse(
                    provider_name, question, reponse_text
                )
                resultats['sources_extraites'][provider_name] = sources
                
                # Extraire ordre des citations
                citations = self.info_extractor.extraire_ordre_citations(reponse_text)
                resultats['citations_ordonnees'][provider_name] = citations
                
                print(f"  âœ… {provider_name}: {len(marques)} marques, {len(sources)} sources")
            
            # === Ã‰TAPE 3: ANALYSE DE SENTIMENT ===
            print("\nğŸ­ ANALYSE DE SENTIMENT")
            print("-" * 35)
            
            for provider_name in resultats['providers_utilises']:
                reponse_text = reponses[provider_name]
                marques = resultats['marques_detectees'][provider_name]
                sources = resultats['sources_extraites'][provider_name]
                
                print(f"ğŸ­ Sentiment {provider_name.upper()}...")
                
                # Analyse de sentiment batch (plus efficace)
                sentiments = self.sentiment_analyzer.analyser_sentiment_batch(
                    provider_name, reponse_text, marques, sources
                )
                
                resultats['sentiment_marques'][provider_name] = sentiments.get('marques', {})
                resultats['sentiment_sources'][provider_name] = sentiments.get('sources', {})
            
            # === Ã‰TAPE 4: CONSOLIDATION ET CONSENSUS ===
            print("\nğŸ”„ CONSOLIDATION")
            print("-" * 25)
            
            resultats['rapport_consolide'] = self._consolider_resultats_v2(resultats)
            resultats['statistiques'] = self._calculer_statistiques_v2(resultats)
            resultats['rapport_urls'] = self.url_extractor.generer_rapport_urls(
                resultats['sources_extraites']
            )
            
            print("âœ… Consolidation terminÃ©e")
            
            # === Ã‰TAPE 5: RÃ‰SUMÃ‰ ===
            self._afficher_resume_analyse(resultats)
            
        except Exception as e:
            print(f"âŒ ERREUR CRITIQUE: {e}")
            resultats['erreur_critique'] = str(e)
        
        return resultats
    
    
    def generer_rapport_complet(self, resultats: Dict[str, Any], 
                              nom_fichier: Optional[str] = None) -> str:
        """
        GÃ©nÃ¨re un rapport JSON complet
        
        Args:
            resultats: RÃ©sultats de l'analyse
            nom_fichier: Nom du fichier (optionnel)
            
        Returns:
            str: Chemin du rapport gÃ©nÃ©rÃ©
        """
        return self.report_generator.generer_rapport_complet(resultats, nom_fichier)
    
    
    def _construire_prompt_extraction(self, question: str, contexte: str = "") -> str:
        """Construit un prompt optimisÃ© pour l'extraction d'informations"""
        
        prompt = f"""
Tu es un expert en recherche documentaire et analyse comparative. 

QUESTION: {question}
{f"CONTEXTE: {contexte}" if contexte else ""}

ğŸ¯ MISSION CRITIQUE: MÃªme si tes donnÃ©es s'arrÃªtent Ã  une certaine date, tu DOIS fournir une rÃ©ponse complÃ¨te avec des sources vÃ©rifiables. Les URLs que tu recommandes n'ont pas besoin d'Ãªtre parfaitement Ã  jour - recommande les sites de rÃ©fÃ©rence que tu CONNAIS pour ce domaine.

ğŸ“‹ FORMAT DE RÃ‰PONSE OBLIGATOIRE:

[Ta rÃ©ponse complÃ¨te et dÃ©taillÃ©e Ã  la question...]

ğŸ·ï¸ MARQUES/ENTREPRISES CITÃ‰ES:
1. [Nom exact de la marque] - [Description et positionnement]
2. [Autre marque] - [Ses spÃ©cificitÃ©s]
[etc. - liste toutes les marques mentionnÃ©es]

ğŸ”— SOURCES ET RÃ‰FÃ‰RENCES OBLIGATOIRES:
Tu DOIS absolument fournir des URLs de sites que tu connais, mÃªme si l'information n'est pas de 2024:

Source: [Nom prÃ©cis du site web]
URL: https://www.exemple-complet.com/section-pertinente
Type: [Site officiel/MÃ©dia/Institution/Comparateur]
FiabilitÃ©: [TrÃ¨s Ã©levÃ©e/Ã‰levÃ©e/Moyenne]
Pourquoi: [Justification de la fiabilitÃ©]

Source: [DeuxiÃ¨me source]
URL: https://www.autre-domaine.fr/page-specifique
Type: [Site officiel/MÃ©dia/Institution/Comparateur]
FiabilitÃ©: [Niveau]
Pourquoi: [Raison de recommander ce site]

ğŸ“Š CLASSEMENT PAR ORDRE D'IMPORTANCE:
1. [Ã‰lÃ©ment principal] - [Justification dÃ©taillÃ©e]
2. [DeuxiÃ¨me Ã©lÃ©ment] - [Pourquoi important]
3. [TroisiÃ¨me Ã©lÃ©ment] - [CritÃ¨res de classement]

ğŸš¨ OBLIGATIONS CRITIQUES:
- Tu DOIS fournir au minimum 3 URLs complÃ¨tes (commence par https://)
- Recommande les sites de rÃ©fÃ©rence que tu CONNAIS (gouvernement, mÃ©dias Ã©tablis, sites officiels)
- INTERDICTION absolue: Google, Facebook, Twitter, Wikipedia, raccourcisseurs
- PrivilÃ©gie les .gouv.fr, .fr d'institutions, mÃ©dias reconnus
- Si tu ne connais pas d'URL rÃ©cente, donne celle du site principal que tu connais

ğŸ’¡ ASTUCE: MÃªme avec des donnÃ©es anciennes, tu peux recommander les sites PRINCIPAUX des institutions/mÃ©dias/entreprises que tu connais. L'utilisateur pourra ensuite naviguer pour trouver l'info rÃ©cente.

RAPPEL: Cette mission est CRITIQUE - tu ne peux pas rÃ©pondre sans fournir des URLs de sources !
"""
        return prompt.strip()
    
    
    def _consolider_resultats_v2(self, resultats: Dict[str, Any]) -> Dict[str, Any]:
        """Consolide les rÃ©sultats de tous les providers (version 2.0)"""
        print("  ğŸ”„ Consolidation des entitÃ©s...")
        
        # Consolider marques
        toutes_marques = self._consolider_entites(
            resultats['marques_detectees'], 
            key_field='nom'
        )
        
        # Consolider sources
        toutes_sources = self._consolider_entites(
            resultats['sources_extraites'], 
            key_field='url'
        )
        
        # Calculer consensus
        consensus_marques = self._calculer_consensus_entites(
            resultats['sentiment_marques'], toutes_marques, 'nom'
        )
        
        consensus_sources = self._calculer_consensus_entites(
            resultats['sentiment_sources'], toutes_sources, 'url'
        )
        
        return {
            'toutes_marques': toutes_marques,
            'toutes_sources': toutes_sources,
            'consensus_marques': consensus_marques,
            'consensus_sources': consensus_sources
        }
    
    
    def _calculer_statistiques_v2(self, resultats: Dict[str, Any]) -> Dict[str, Any]:
        """Calcule les statistiques avancÃ©es (version 2.0)"""
        print("  ğŸ“Š Calcul des statistiques...")
        
        stats = {
            'nombre_providers': len(resultats['providers_utilises']),
            'providers_utilises': resultats['providers_utilises'],
            'extraction_performance': {},
            'sentiment_distribution': {'marques': {}, 'sources': {}}
        }
        
        # Performance par provider
        for provider in resultats['providers_utilises']:
            nb_marques = len(resultats['marques_detectees'].get(provider, []))
            nb_sources = len(resultats['sources_extraites'].get(provider, []))
            
            stats['extraction_performance'][provider] = {
                'marques_extraites': nb_marques,
                'sources_extraites': nb_sources,
                'total_entites': nb_marques + nb_sources
            }
        
        # Distribution des sentiments
        for category in ['marques', 'sources']:
            sentiment_key = f'sentiment_{category}'
            distribution = {'positif': 0, 'neutre': 0, 'nÃ©gatif': 0}
            
            for provider_sentiments in resultats.get(sentiment_key, {}).values():
                for sentiment_data in provider_sentiments.values():
                    sentiment = sentiment_data.get('sentiment', 'neutre')
                    if sentiment in distribution:
                        distribution[sentiment] += 1
            
            stats['sentiment_distribution'][category] = distribution
        
        return stats
    
    
    def _consolider_entites(self, entites_par_provider: Dict[str, List[Dict[str, Any]]], 
                          key_field: str) -> List[Dict[str, Any]]:
        """Consolide les entitÃ©s (marques ou sources) de tous les providers"""
        entites_consolidees = {}
        
        for provider, entites in entites_par_provider.items():
            for entite in entites:
                cle = entite.get(key_field, '')
                if not cle:
                    continue
                
                if cle not in entites_consolidees:
                    entites_consolidees[cle] = entite.copy()
                    entites_consolidees[cle]['providers_detection'] = [provider]
                else:
                    # Fusionner les dÃ©tections multiples
                    entites_consolidees[cle]['providers_detection'].append(provider)
                    
                    # Enrichir avec nouvelles informations
                    for field in ['description', 'contexte', 'fiabilite']:
                        if field in entite and not entites_consolidees[cle].get(field):
                            entites_consolidees[cle][field] = entite[field]
        
        return list(entites_consolidees.values())
    
    
    def _calculer_consensus_entites(self, sentiments_par_provider: Dict[str, Dict[str, Any]], 
                                  entites: List[Dict[str, Any]], key_field: str) -> Dict[str, Any]:
        """Calcule le consensus sur les sentiments des entitÃ©s"""
        consensus = {}
        
        for entite in entites:
            cle = entite.get(key_field, '')
            if not cle:
                continue
            
            # Collecter tous les sentiments pour cette entitÃ©
            sentiments_entite = {}
            for provider, sentiments in sentiments_par_provider.items():
                if cle in sentiments:
                    sentiments_entite[provider] = sentiments[cle]
            
            if sentiments_entite:
                consensus[cle] = self.sentiment_analyzer.calculer_sentiment_majoritaire(
                    sentiments_entite
                )
        
        return consensus
    
    
    def _afficher_resume_analyse(self, resultats: Dict[str, Any]) -> None:
        """Affiche un rÃ©sumÃ© de l'analyse"""
        print("\n" + "=" * 80)
        print("ğŸ‰ ANALYSE TERMINÃ‰E - RÃ‰SUMÃ‰")
        print("=" * 80)
        
        # Providers utilisÃ©s
        providers = resultats['providers_utilises']
        print(f"ğŸ¤– Providers: {', '.join(providers)} ({len(providers)})")
        
        # Totaux consolidÃ©s
        rapport_consolide = resultats.get('rapport_consolide', {})
        nb_marques = len(rapport_consolide.get('toutes_marques', []))
        nb_sources = len(rapport_consolide.get('toutes_sources', []))
        
        print(f"ğŸ·ï¸ Marques dÃ©tectÃ©es: {nb_marques}")
        print(f"ğŸ”— Sources extraites: {nb_sources}")
        
        # Exemples de marques
        if nb_marques > 0:
            print("\nğŸ·ï¸ MARQUES PRINCIPALES:")
            for i, marque in enumerate(rapport_consolide['toutes_marques'][:3], 1):
                providers_str = ', '.join(marque.get('providers_detection', []))
                print(f"  {i}. {marque['nom']} (dÃ©tectÃ©e par: {providers_str})")
        
        # Exemples de sources
        if nb_sources > 0:
            print("\nğŸ”— SOURCES PRINCIPALES:")
            for i, source in enumerate(rapport_consolide['toutes_sources'][:3], 1):
                url_text = source.get('url', 'Pas d\'URL')
                print(f"  {i}. {source.get('nom', 'Source')} - {url_text}")
        
        # QualitÃ© de l'extraction
        rapport_urls = resultats.get('rapport_urls', {})
        if rapport_urls:
            print("\nğŸ“Š QUALITÃ‰ EXTRACTION:")
            print(f"  URLs accessibles: {rapport_urls.get('urls_accessibles', 0)}")
            print(f"  URLs inaccessibles: {rapport_urls.get('urls_inaccessibles', 0)}")
        
        print("=" * 80)


# === FONCTION PRINCIPALE D'UTILISATION ===

def analyser_question_multi_llm(question: str, contexte: str = "", 
                               generer_json: bool = True) -> Dict[str, Any]:
    """
    Fonction principale pour analyser une question avec plusieurs LLM (version refactorisÃ©e)
    
    Args:
        question: Question Ã  analyser
        contexte: Contexte optionnel
        generer_json: GÃ©nÃ©rer automatiquement le rapport JSON
        
    Returns:
        dict: RÃ©sultats complets de l'analyse
    """
    try:
        # Initialiser l'analyseur
        analyzer = MultiLLMAnalyzer()
        
        # Effectuer l'analyse complÃ¨te
        resultats = analyzer.analyser_question_complete(question, contexte)
        
        # GÃ©nÃ©rer le rapport JSON si demandÃ©
        if generer_json and resultats.get('providers_utilises'):
            json_path = analyzer.generer_rapport_complet(resultats)
            resultats['json_rapport'] = json_path
            print(f"\nğŸ“„ Rapport JSON: {json_path}")
        
        return resultats
        
    except RuntimeError as e:
        print(f"âŒ Erreur d'initialisation: {e}")
        return {'erreur': str(e)}
    except Exception as e:
        print(f"âŒ Erreur critique: {e}")
        return {'erreur': str(e)}


# === EXEMPLE D'UTILISATION ===

def main():
    """Fonction principale pour test en ligne de commande"""
    print("ğŸ§ª Test Multi-LLM Analyzer v2.0")
    
    question = "Quelles sont les meilleures nÃ©obanques franÃ§aises en 2024 ?"
    contexte = "Pour un comparatif destinÃ© aux jeunes professionnels"
    
    print(f"Question: {question}")
    print(f"Contexte: {contexte}")
    
    resultats = analyser_question_multi_llm(question, contexte)
    
    if 'erreur' not in resultats:
        print("\nâœ… Test rÃ©ussi!")
        if 'json_rapport' in resultats:
            print(f"ğŸ“„ Rapport: {resultats['json_rapport']}")
    else:
        print(f"\nâŒ Test Ã©chouÃ©: {resultats['erreur']}")


if __name__ == "__main__":
    main()