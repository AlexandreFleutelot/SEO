# -*- coding: utf-8 -*-
"""
page_analyzer.py

Ce script est l'orchestrateur principal de l'outil d'analyse SEO.
Il importe les fonctions d'analyse des diff√©rents modules de cat√©gories
et g√©n√®re un rapport complet pour une URL donn√©e.

Pour que ce script fonctionne, assurez-vous que les fichiers suivants
sont dans le r√©pertoire utils:
- content.py
- structure.py
- linking.py
- performance.py
- aio.py

D√©pendances √† installer :
pip install requests beautifulsoup4 spacy datefinder

Mod√®le de langue pour le fran√ßais :
python -m spacy download fr_core_news_sm
"""

import requests
import json
import os
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# --- Importation des fonctions d'analyse depuis les modules de cat√©gories ---
from .utils.content import (
    get_main_text,
    analyze_richness_and_coverage,
    analyze_style_clarity,
    analyze_sources_reliability,
    analyze_freshness
)
from .utils.structure import (
    analyze_hn_structure,
    analyze_metadata,
    analyze_images_optimization,
    analyze_structured_data,
    analyze_crawlability
)
from .utils.linking import analyze_internal_linking
from .utils.performance import analyze_core_web_vitals
from .utils.aio import (
    analyze_atomicity_direct_answer,
    analyze_quantifiable_data,
    analyze_expertise_signals,
    analyze_multimodal_interoperability
)
from .utils.llm_analysis import analyze_llm_content
from .utils.enhanced_content import analyze_enhanced_content
from .utils.enhanced_structure import analyze_enhanced_structure
from .utils.scoring import generate_score_report
from .utils.page_storage import save_page_content, cleanup_old_pages


def analyze_full_page(url, pagespeed_api_key=None):
    """
    Orchestre l'analyse compl√®te d'une page web en appelant toutes les fonctions
    des modules de cat√©gories.
    
    Args:
        url (str): L'URL de la page √† analyser.
        pagespeed_api_key (str, optional): La cl√© API pour Google PageSpeed Insights.
                                           Si None, cette analyse sera ignor√©e.

    Returns:
        dict: Un dictionnaire contenant le rapport d'analyse complet.
    """
    print(f"üöÄ D√©marrage de l'analyse compl√®te pour : {url}")
    
    final_report = {'url': url, 'analysis_results': {}}

    # --- √âtape 1: R√©cup√©ration du contenu de la page ---
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Sauvegarder la page t√©l√©charg√©e
        try:
            save_page_content(url, response.text, dict(response.headers))
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la sauvegarde de la page: {e}")
        
        # Cr√©er une copie de la soup pour l'analyse textuelle afin de ne pas affecter les autres analyses
        text_soup = BeautifulSoup(str(soup), 'html.parser')
        main_text = get_main_text(text_soup)
        print("‚úÖ Contenu de la page r√©cup√©r√© avec succ√®s.")
    except requests.RequestException as e:
        print(f"‚ùå Erreur critique : Impossible de r√©cup√©rer la page. {e}")
        final_report['error'] = str(e)
        return final_report

    # --- √âtape 2: Lancement des analyses par cat√©gorie ---
    
    # Cat√©gorie 1: Contenu & S√©mantique
    try:
        final_report['analysis_results']['category_1_content'] = {
            '1.1_richness_coverage': analyze_richness_and_coverage(main_text),
            '1.2_style_clarity': analyze_style_clarity(soup),
            '1.3_sources_reliability': analyze_sources_reliability(soup, url),
            '1.4_freshness': analyze_freshness(soup)
        }
        print("üìä Cat√©gorie 1 (Contenu) analys√©e.")
    except Exception as e:
        final_report['analysis_results']['category_1_content'] = {'error': str(e)}

    # Cat√©gorie 2: Structure
    try:
        final_report['analysis_results']['category_2_structure'] = {
            '2.1_hn_structure': analyze_hn_structure(soup),
            '2.2_metadata': analyze_metadata(soup),
            '2.3_images_optimization': analyze_images_optimization(soup),
            '2.4_structured_data': analyze_structured_data(soup),
            '2.5_crawlability': analyze_crawlability(url)
        }
        print("üèóÔ∏è  Cat√©gorie 2 (Structure) analys√©e.")
    except Exception as e:
        final_report['analysis_results']['category_2_structure'] = {'error': str(e)}

    # Cat√©gorie 3: Maillage & Liens
    try:
        final_report['analysis_results']['category_3_linking'] = {
            '3.1_3.2_internal_linking': analyze_internal_linking(soup, url)
        }
        print("üîó Cat√©gorie 3 (Maillage) analys√©e.")
    except Exception as e:
        final_report['analysis_results']['category_3_linking'] = {'error': str(e)}

    # Cat√©gorie 4: Performance Technique
    try:
        print("‚è±Ô∏è  Analyse de la Cat√©gorie 4 (Performance) en cours (peut prendre du temps)...")
        final_report['analysis_results']['category_4_performance'] = {
            '4.1_4.2_desktop_performance': analyze_core_web_vitals(url, pagespeed_api_key, 'DESKTOP'),
            '4.1_4.2_mobile_performance': analyze_core_web_vitals(url, pagespeed_api_key, 'MOBILE')
        }
        print("‚ö° Cat√©gorie 4 (Performance) analys√©e.")
    except Exception as e:
        final_report['analysis_results']['category_4_performance'] = {'error': str(e)}

    # Cat√©gorie 5: Optimisation AIO
    try:
        final_report['analysis_results']['category_5_aio'] = {
            '5.1_atomicity_direct_answer': analyze_atomicity_direct_answer(soup),
            '5.2_quantifiable_data': analyze_quantifiable_data(main_text),
            '5.3_expertise_signals': analyze_expertise_signals(soup),
            '5.4_multimodal_interoperability': analyze_multimodal_interoperability(soup)
        }
        print("ü§ñ Cat√©gorie 5 (AIO) analys√©e.")
    except Exception as e:
        final_report['analysis_results']['category_5_aio'] = {'error': str(e)}

    # --- CAT√âGORIE 6 : AI-POWERED CONTENT ANALYSIS ---
    try:
        print("üß† Analyse de la Cat√©gorie 6 (AI Content Analysis) en cours...")
        final_report['analysis_results']['category_6_llm_analysis'] = analyze_llm_content(soup, main_text, url)
        print("üß† Cat√©gorie 6 (AI Content Analysis) analys√©e.")
    except Exception as e:
        final_report['analysis_results']['category_6_llm_analysis'] = {'error': str(e)}
        print(f"‚ö†Ô∏è  Erreur lors de l'analyse LLM: {str(e)}")

    # --- ANALYSES AM√âLIOR√âES ---
    try:
        print("üîç Analyses de contenu am√©lior√©es en cours...")
        final_report['analysis_results']['enhanced_content_analysis'] = analyze_enhanced_content(soup, main_text)
        print("üîç Analyses de contenu am√©lior√©es termin√©es.")
    except Exception as e:
        final_report['analysis_results']['enhanced_content_analysis'] = {'error': str(e)}
        print(f"‚ö†Ô∏è  Erreur lors de l'analyse de contenu am√©lior√©e: {str(e)}")

    try:
        print("üèóÔ∏è  Analyses de structure am√©lior√©es en cours...")
        final_report['analysis_results']['enhanced_structure_analysis'] = analyze_enhanced_structure(url, soup)
        print("üèóÔ∏è  Analyses de structure am√©lior√©es termin√©es.")
    except Exception as e:
        final_report['analysis_results']['enhanced_structure_analysis'] = {'error': str(e)}
        print(f"‚ö†Ô∏è  Erreur lors de l'analyse de structure am√©lior√©e: {str(e)}")

    print("\nüéâ Analyse compl√®te termin√©e !")
    return final_report


# --- Exemple d'utilisation du script ---
def main():
    """Fonction principale pour l'analyse SEO."""
    # --- CONFIGURATION ---
    # URL de la page que vous souhaitez analyser (depuis l'environnement ou par d√©faut)
    TARGET_URL = os.getenv('ANALYSIS_URL', "https://www.meilleurtaux.com/credit-immobilier/actualites/2025-aout/ete-favorable-emprunteurs-immobiliers.html")
    
    # Configuration des options d'analyse
    ENABLE_LLM_ANALYSIS = os.getenv('ENABLE_LLM_ANALYSIS', 'true').lower() == 'true'
    ENABLE_ENHANCED_ANALYSIS = os.getenv('ENABLE_ENHANCED_ANALYSIS', 'true').lower() == 'true'
    
    # (Optionnel) Cl√© API Google PageSpeed Insights charg√©e depuis .env
    # Pour en obtenir une, suivez les instructions sur :
    # https://developers.google.com/speed/docs/insights/v5/get-started
    # Si vous n'en mettez pas dans .env, l'analyse de performance sera ignor√©e.
    PAGESPEED_API_KEY = os.getenv('PAGESPEED_API_KEY') 
    
    print(f"üéØ URL √† analyser: {TARGET_URL}")
    print(f"üß† Analyse LLM: {'‚úÖ Activ√©e' if ENABLE_LLM_ANALYSIS else '‚ùå D√©sactiv√©e'}")
    print(f"üî¨ Analyse am√©lior√©e: {'‚úÖ Activ√©e' if ENABLE_ENHANCED_ANALYSIS else '‚ùå D√©sactiv√©e'}")
    print(f"‚ö° API PageSpeed: {'‚úÖ Configur√©e' if PAGESPEED_API_KEY else '‚ùå Non configur√©e'}")
    print("-" * 60)

    # --- Lancement de l'analyse ---
    full_report = analyze_full_page(TARGET_URL, PAGESPEED_API_KEY)
    
    # --- Affichage du rapport ---
    print("\n--- RAPPORT D'ANALYSE SEO & AIO COMPLET ---")
    # Utiliser json.dumps pour un affichage propre et lisible du dictionnaire
    print(json.dumps(full_report, indent=4, ensure_ascii=False))
    
    # (Optionnel) Sauvegarder le rapport dans un fichier JSON
    try:
        report_filename = f"reports/raw/report_{TARGET_URL.split('//')[1].replace('/', '_')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, indent=4, ensure_ascii=False)
        print(f"\n‚úÖ Rapport raw sauvegard√© dans le fichier : {report_filename}")
        
        # G√©n√©rer automatiquement le rapport de scores
        try:
            print("üìä G√©n√©ration du rapport de scores...")
            score_report = generate_score_report(report_filename)
            
            # Afficher un r√©sum√© des scores
            global_analysis = score_report["global_analysis"]
            print(f"\nüéØ Score Global SEO: {global_analysis['global_score']}/100")
            print(f"üìä Niveau de Performance: {global_analysis['performance_level']}")
            
            if global_analysis['strengths']:
                print(f"üí™ Forces: {', '.join(global_analysis['strengths'])}")
            if global_analysis['weaknesses']:
                print(f"‚ö†Ô∏è  Faiblesses: {', '.join(global_analysis['weaknesses'])}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors de la g√©n√©ration des scores : {e}")
            
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la sauvegarde du rapport : {e}")
    
    # Nettoyage automatique des anciennes pages (optionnel)
    try:
        print("üßπ Nettoyage des anciennes pages...")
        cleanup_old_pages(max_pages=50, max_days=30)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du nettoyage: {e}")


if __name__ == '__main__':
    main()
